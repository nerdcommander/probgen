[
["index.html", "Probability and Genetics Preface 0.1 Motivation 0.2 About the Authors", " Probability and Genetics Bill Bynum and Brian Avery 2018-01-13 Preface 0.1 Motivation 0.2 About the Authors "],
["basics.html", "Chapter 1 Coin flips and Chromosomes - Probability Basics and Tree Diagrams 1.1 Introduction 1.2 Chapter Scenario 1.3 Terminology 1.4 Simulation 1.5 Tree Diagrams 1.6 The Urn Model 1.7 Ands, Ors, and Nots 1.8 Appendix 1: Genetics Examples", " Chapter 1 Coin flips and Chromosomes - Probability Basics and Tree Diagrams 1.1 Introduction In this chapter, basic terminology and principles of probability are introduced along with simulation and tree diagrams as important tools to analyze probability questions. 1.2 Chapter Scenario Imagine a simple situation where two coins are tossed and the number of heads is observed and the outcome has some relevance for you depending on whether the result yields 0, 1, or 2 heads. Do you think each of these outcomes is equally likely? What do you think is the probability of each of these outcomes? We use this coin-flipping scenario as a primary example not because we have inherent interest flipping coins but because this scenario is an effective model for many real-world situations such as gene inheritance. 1.3 Terminology Probability is the measure of the likelihood of an event on a scale of 0 to 1 where a probability of 1 can be interpreted as certainty the event will occur and a probability of 0 interpreted as certainty the event will NOT occur. There are two main schools of thought regarding what probability is - the frequentist and the bayesian - but for our initial purposes we will think of the probability of an event as the relative frequency of its occurrence in the long run. In very informal shorthand, we think of probability as the ratio of successes to the total number of trials as shown below but must be careful to distinguish between exact theoretical probabilities and approximate empirical probabilities. \\[Probability = \\frac{successes}{total}\\] Consider a coin is flipped and we examine whether it lands on heads or tails. We say it is a fair coin if heads and tails are equally likely. In this case, the probability of the coin landing on heads is \\(1/2\\) which can also be expressed as \\(0.5\\) or \\(50\\%\\) meaning that as the experiment is repeated the proportion of heads ultimately approaches 0.50. It does not mean that in any number of trials we will obtain heads exactly \\(50\\%\\) of the time as samples will vary. A probability experiment is a process with a random element producing a well-defined outcome such as the tossing of a coin described above and the chapter scenario described above where two coins are flipped and you are interested in whether 0, 1, or 2 heads are seen. An event is any well-defined outcome of the probability experiment, such as, the outcome of getting at least one head when flipping two coins. We often use function notation when describing probabilities. For event E in a probability experiment we will use P(E) to represent the probability event E occurs. We also informally use short descriptions of events combined with probability function notation. For example, when flipping one coin we can note \\(P(heads)=1/2\\). The sample space is a list of all possible outcomes of a probability experiment. One desirable property of a sample space description is that the simple events we use are equally likely, meaning all have the same probability of occurring. For example, for the experiment of flipping two coins one might consider \\(\\{0\\,heads,\\,1\\, head,\\,2\\,heads\\}\\) as a potential sample space but enquiring minds might wonder whether or not each of these outcomes is equally likely. 1.4 Simulation Simulation is often a helpful tool to explore probability questions like the question above regarding whether getting 0, 1, or 2 heads when flipping two coins are all equally likely. The code below simulates 10,000 trials of two coin flips keeping track of the number of heads, number of tails, and proportion of heads for each trial. sim_2 &lt;- do(10000)*rflip(n=2, prob=1/2) knitr::kable( head(sim_2), caption = &#39;Table 1: Two Coin Simulation&#39;, booktabs = TRUE ) Table 1.1: Table 1: Two Coin Simulation n heads tails prop 2 0 2 0.0 2 0 2 0.0 2 1 1 0.5 2 2 0 1.0 2 1 1 0.5 2 2 0 1.0 The result is visualized in a histogram of the heads variable showing the frequency of obtaining 0, 1, and 2 heads. ggplot(data=sim_2, aes(x=heads)) + geom_histogram(aes(y=..density..), binwidth = 1) Figure 1.1: Histogram for Number of Heads When Flipping Two Coins Examining the histogram we see that obtaining one head is more likely than the other two options and, thus, getting 0, 1, and 2 heads when flipping two coins are not equally likely outcomes. Prompted by the results of the simulation, we want to know why getting one head is more likely and tree diagrams will help us. 1.5 Tree Diagrams The outcomes of a probability experiment can be catalogued with a tree diagram where at each node the different branches represent the different possible outcomes at each stage of the process. Consider the tree diagram for flipping a single coin where we label each node as either H for Heads or T for tails and label the probability along each branch. Figure 1.2: Tree Diagram for One Coin Including the possible outcomes for a second coin results in a tree diagram with four branches. Figure 1.3: Tree Diagram for Two Coins Each path from the top of the tree to the bottom represents one possible outcome when tossing two coins. In this experiment, there is a 50/50 chance of getting heads or tails thus all four paths are equally likely each occurring with probability \\(0.5 \\times 0.5 = 0.25\\). If we think of the probability associated with each branch as the proportion of the time we travel down that branch then multiplying these probabilities makes perfect sense to determine the probability of traveling down sequential branches. We can now understand why getting one head is more likely as there are two paths, HT and TH, compared to only one path generating zero heads, TT, and only one path generating two heads, HH, resulting in the following probabilities: \\[P(0\\ heads) = P(TT) = (0.5)(0.5) = 0.25\\] \\[\\small P(1\\ head) = P(TH\\ or\\ HT) = P(TH) + P(HT) = (0.5)(0.5) + (0.5)(0.5) = 0.25 + 0.25 = 0.5\\] \\[P(2\\ heads) = P(HH) = (0.5)(0.5) = 0.25\\] 1.5.1 An Example with Rats Now consider the experiment of choosing three rats at random from a large population of rats that is 40% male and 60% female. Just as we did for coins, we can draw a tree diagram with branches representing the sex of the first, second, and third rat chosen and label the associated probabilities on each branch. Selecting the rats and identifying gender would be equivalent to having a coin that lands on one side 40% of the time and on the other 60% of the time. In the tree diagram below, we have added subscripts to identify whether we are referring to the first, second, or third rat selected. Figure 1.4: Tree Diagram for Three Rats What is the probability of selecting 0 female rats? Note that because the population is large at each stage of the process the probability of selecting a female rat is 0.60. \\[P(0\\ female\\ rats) = P(M_{1}\\ and\\ M_{2}\\ and\\ M_{3}) = (0.4) \\times (0.4) \\times (0.4) = 0.064\\] What is the probability of selecting 1 female rat? There are actually three distinct paths through the tree where 1 female rat and 2 male rats are selected and each one has the probability \\((0.6) \\times (0.4)^2\\) thus the probability is \\[P(1\\ female\\ rat) = 3 \\times (0.6) (0.4)^2 = 0.288\\] 1.5.1.1 Practice Exercise 1 For the probability experiment described above choosing three rats at random from a large population of rats that is 40% male and 60% female, what is the probability of getting 2 female rats? 3 female rats? 1.5.1.2 Practice Exercise 2 Draw a tree diagram for the probability experiment of flipping three coins. Label each node as either H for Heads or T for tails and label the probability along each branch. Find the probabilities of obtaining exactly 0 heads, 1 head, 2 heads, and 3 heads. 1.6 The Urn Model When confronted with a question of personal importance to you where probabilistic concerns are relevant to getting an accurate answer, the ability to develop a model that captures important probability details is a key problem-solving tool. By model we mean a systematic description that shares all of the important characterics of the problem, be it a physical, visual, mathematical, or computational representation (http://www.dictionary.com/browse/model). For probability experiments two useful models are the coin-flipping model and the urn model. We have already looked briefly at a coin-flipping experiment. We will see throughout our probabilistic treatment of genetics that we will often use coin-flipping as a mental model to think about questions of genetic risk and reward. The urn model is another important way to think about probability questions. Consider an urn with some beads in it. Imagine the urn has 20 beads 12 of which are black and 8 white and we are to draw out three of these beads at random and we want to find the probability of ending up with 0, 1, 2, or 3 black beads. Figure 1.5: The Urn Model First, we need to be clear up one question: is the drawing out of beads to be done with replacement or without replacement? By with replacement we mean that after each draw of one bead, it is replaced, the beads thoroughly mixed, before another bead is selected at random. By without replacement we mean that after one bead is removed, it is not replaced before the next bead is selected. Note, if we are selecting three beads at once this could be viewed as equivalent to selecting the beads one at a time without replacement. Figure 1.6: Tree Diagram for Three Beads For this experiment with three beads drawn at random without replacement from an urn containing 12 black and 8 white beads, what is the probability of ending up with 0, 1, 2, or 3 black beads, respectively? First, let’s tackle the probability of getting 0 black beads. From examining the tree we see \\[P(0\\ blacks) = P(W_{1}\\ and\\ W_{2}\\ and\\ W_{3}) = \\frac{8}{20} \\times \\frac{7}{19} \\times \\frac{6}{18}\\] Finding the probability of one black is more work. As we examine the tree we see there are three distinct paths resulting in one black. Check out their separate probabilities here. \\[P(B_{1}\\ and\\ W_{2}\\ and\\ W_{3}) = \\frac{12}{20} \\times \\frac{8}{19} \\times \\frac{7}{18} = 0.098\\] \\[P(W_{1}\\ and\\ B_{2}\\ and\\ W_{3}) = \\frac{8}{20} \\times \\frac{12}{19} \\times \\frac{7}{18} = 0.098\\] \\[P(W_{1}\\ and\\ W_{2}\\ and\\ B_{3}) = \\frac{8}{20} \\times \\frac{7}{19} \\times \\frac{12}{18} = 0.098\\] In spite of the numerators being in different orders, we notice that these three separate probabilities are numerically equal. Thus, for the final probability we see \\[P(1\\ black) = 3 \\times \\frac{12}{20} \\times \\frac{8}{19} \\times \\frac{7}{18} = 0.295\\] 1.7 Ands, Ors, and Nots Most of the interesting probability questions involve combinations of simple events. In this section we examine the probabilities of two events both occurring (and), at least one of two events occurring (or), as well as an event not occurring (not). 1.7.1 In an Attempt to Kill the Student, the Authors Solve the Same Simple Problem Four Ways (One Bad and Three Good) By dissecting an easy problem we can gain insight into multiple problem-solving strategies that can be useful in other problems. Or we can kill motivation altogether. We will see. In the game of Risk competitors resolve attacks by rolling dice. Suppose that you are rolling two dice and you are interested in whether or not we obtain a six. We consider the following compound events. While there are six sides to each die, because we are primarily interested in whether or not we obtain a six, we will use the tree diagram below where event S represents getting a six and event N represents getting a non-six, ie., 1, 2, 3, 4, or 5. Figure 1.7: Tree Diagram for Sixes on Two Dice Even if we are tossing identical dice simultaneously it is helpful to conceptualize the experiment as if we are tossing the dice sequentially. We have added subscripts to identify whether we are referring to the first die tossed or the second die tossed. What is the probability of obtaining a six on both dice? Because the two events of getting a six on the first die and getting a six on the second die are independent, we can use The Multiplication Rule for Independent Events which says for any two independent events \\(E\\) and \\(F\\), \\(P(E\\ and\\ F) = P(E) \\times P(F)\\). \\[P(two\\ sixes) = P(S_{1}\\ and\\ S_{2}) = P(S_{1}) \\times P(S_{2}) = \\frac{1}{6} \\times \\frac{1}{6}\\] What is the probability of obtaining a six on at least one of the two dice? We examine this problem from four points of view - the wrong point of view, the addition rule, the partition technique, and the complement principle. 1.7.1.1 The Wrong Way Here is a faulty answer: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ or\\ S_{2}) = P(S_{1})+ P(S_{2}) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = \\frac{1}{3}\\ \\ WRONG!\\] Can you spot the problem? The issue is that one branch with a six on both dice, the overlap where both events \\(S_{1}\\) and \\(S_{2}\\) occur, was counted twice. 1.7.1.2 The Addition Rule Here is a correct version using what is called The Addition Rule where the overlap, since it was counted twice, is subtracted: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ or\\ S_{2}) = P(S_{1})+ P(S_{2}) - P(S_{1}\\ AND\\ S_{2}) =\\\\ \\frac{1}{6} + \\frac{1}{6} - \\frac{1}{6} \\times \\frac{1}{6} = \\frac{11}{36}\\] 1.7.1.3 The Partition Approach An alternative approach is to partition the event into mutually exclusive parts. We might informally describe this approach as divide and conquer. In this case, there are three distinct branches that satisfy at least one six occurring: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ and\\ N_{2}) + P(N_{1}\\ and\\ S_{2}) + P(S_{1}\\ and\\ S_{2}) = \\\\ \\frac{1}{6} \\times \\frac{5}{6} + \\frac{5}{6} \\times \\frac{1}{6} + \\frac{1}{6} \\times \\frac{1}{6} = \\frac{11}{36}\\] 1.7.1.4 The Complement Principle A third correct approach uses The Complement Principle which observes that for any event \\(E\\), \\(P(E) = 1 - P(not\\ E)\\). In this situation, we note \\(P(at\\ least\\ one) = 1 - P(none)\\). Sometimes it is less work to find the complement of an event and subtract from one. \\[P(at\\ least\\ one\\ six) = 1 - P(no\\ sixes) = 1 - P(N_{1}\\ and\\ N_{2}) = \\\\ 1 - \\frac{5}{6} \\times \\frac{5}{6} = \\frac{11}{36}\\] To summarize what we have learned about problem-solving here, there is more than one way to solve a probability problem (and some ways are wrong!). But several good strategies to use are the addition rule being careful not to double-count, divide and conquer by partitioning the event into mutually exclusive pieces, or use the complement principle to solve the opposite problem and subtract this from one. 1.8 Appendix 1: Genetics Examples In this appendix, you are introduced to the absolute basic terminology of genetics and how the principles of probability that you learned in chapter 1 can be applied to genetics. We are going to adapt the examples from the main part of chapter 1 to genetics. We’ll look at some of the same tree diagrams and simulations but within a simple genetics framework (rather than coin flips and urns). 1.8.1 Genetics Terminology For now, we are going to use the minimum of genetic lingo to get going: trait: a characteristic, something you can see or measure (e.g. height, Huntington’s disease) gene: the DNA that controls a trait (e.g. hemoglobin beta gene) usually shown with a letter or letters (e.g. Hb) variant: one of several versions of a gene (e.g. HbS variant in hemoglobin beta that can cause Sickle Cell Anemia but there are other variants of the same gene (HbC, HbE, etc.), a.k.a. allele) chromosome: long, continuous stretch of DNA that contains many genes (humans have 2 copies of each of 22 numbered chromosomes and either 2 X chromosomes for females or an X and a Y for males) gamete: specialized cell that has only 1 copy of each chromosome that is used during sexual reproduction (e.g. egg or sperm) 1.8.2 Genetics Basics 1.8.2.1 intro to chromosomal genetics humans have 2 copies of every gene (can be same variant or different) meiosis is the process of making gametes with only 1 copy of all of the genes fertilization fuses two gametes each with 1 copy back into a cell/organism with 2 copies (1 from each parent/gamete) To summarize the important points about meiosis, parents each make gametes that contain only one of their 2 possible copies of each chromosome. Then the gametes can fuse together by fertilization to make the offspring (next generation) that again has 2 copies of each chromosome (one from each of their parents). Below are some cartoons of meiosis starting with an example cell that has 2 chromosomes (one with the A gene and a second with the B gene) and this organism has 2 copies of each chromosome. Figure 1.8: cartoon example cell Notice that the chromosomes have different variants. When that cell goes through meiosis, it produces gametes that have one copy of each of the 2 different chromosomes. Figure 1.9: making gametes Compare the original/parent and gamete and convince yourself that this gamete has one of each of the different chromosomes in the original/parent organism. Notice that the figure below says that the gamete shown is only one of the possibilities. If you like to think ahead, what are the other possibilities? If you’re not up for it yet, don’t worry, we’ll get there. To make an offspring, 2 gametes fuse by fertilization. Figure 1.10: fertilization Since each gamete has only 1 copy of each chromosome, when 2 gametes fuse, there are again 2 copies of each chromosome (one from each of their parents). So, new humans have 2 chromosomes, one from each parent. 1.8.2.2 thinking probilitisically To wrap this back around to probability and tree diagrams, you can think of each parent as having a coin for each chromosome, and each chromosome-coin has 2 sides - H and T for a coin, one for each copy of the chromosome (A1 or A2). The chromosome version is equally likely to fall on the A1 or A2 “side” (as long as we only consider one gene on each chromosome, which we will do for now). So, our tree diagram looks like this: Figure 1.11: one chromosome tree - first parent Now if we think of the gametes from the second parent as a second “coin” with A1 and A2 “sides”, our tree diagram looks like this: Figure 1.12: one chromosome tree - second parent Then we can use the multiplication rule to find the probabilities of the different offspring as seen below: Figure 1.13: one chromosome tree - offspring We can also use the addition rule to clean up our prediction a bit since most of the time it doesn’t matter which parent you get an allele from, so A1A2 and A2A1 are equivalent and we can add their probabilities together to get a combined \\(p(A1A2)=0.5\\). Also notice that in the tree diagrams and in parentheses in the meiosis drawings that we often just write the gene/variant shorthand. This shorthand is called the genotype and is pretty useful since it can save you from drawing a lot of chromosomes, but if you need the chromosomes to be sure you understand what’s going on, feel free to sketch away. 1.8.2.3 intro to DNA There are 4 main DNA letters (a.k.a. bases) - A, T, C, G - that make up genes, which can be thought of as DNA “words”. While it’s not my favorite analogy, it works reasonably well - genes are collections of DNA information. There are variants (different versions) of genes that change the letters, and many of those change the information the gene contains, and can change the organism. 1.8.2.4 genetic “notation” Geneticists (a lot like mathematicians) use abbreviations as short cuts a lot. They are first introduced above in the Genetics Terminology section, and again discussed at the end of the Thinking Probabilistically section but we’ll lay it out more here. Every gene has an abbreviated name (like a nickname) that makes it easier to write. For example, the hemoglobin beta gene goes by Hb. We use that as a base, then we add other letters to modify this name to show that we are talking about specific variants like the HbS variant in hemoglobin beta that can cause sickle cell anemia. Just to break that down, the Hb part tells us the gene, and the S part tells us which variant. Sometimes we will use numbers, such as A1 and A2 to mean the 1 and 2 variants of the A gene, or for other genes we’ll use lowercase and uppercase, such as B and b, to mean different variants of the same gene. And as a review, writing just the letter shorthand for all of the genes and variants together is the genotype of an organism. 1.8.3 Genetics Simulation Now we’ll use R to simulate the same situation shown in the tree diagram above. This version takes the long way around, but it conceptually models meiosis (gamete formation) and fertilization for 1000 offspring. Our first set of parents have the genotypes below: parent 1: A1/A1 parent 2: A2/A2 The code below simulates meiosis and fertilization of 1000 offspring, makes a table, and graphs the results. # set up the different variants that each parent has parent1_variants &lt;- c(&#39;A1&#39;,&#39;A1&#39;) parent2_variants &lt;- c(&#39;A2&#39;,&#39;A2&#39;) # list of 1000 gametes from each parent, probability of each is equal by default parent1_gametes &lt;- sample(parent1_variants, 1000, replace = TRUE) parent2_gametes &lt;- sample(parent2_variants, 1000, replace = TRUE) # put gametes together to make 1000 offspring cross_x1 &lt;- paste(parent1_gametes, parent2_gametes, sep=&quot;/&quot;) offspring1 &lt;- data.frame(table(cross_x1)) # table knitr::kable(offspring1, caption = &#39;A1xA2 parent cross simulation&#39;, booktabs = TRUE) Table 1.2: A1xA2 parent cross simulation cross_x1 Freq A1/A2 1000 # makes a bar graph of the frequency of genotypes ggplot(offspring1, aes(x=cross_x1, y=Freq)) + geom_bar(stat=&quot;identity&quot;) Now that we have the results for that set of offspring (all have the A1/A2 genotype), we can look at these offspring as parents for a new generation of offspring. Now the parents are: parent 1: A1/A2 parent 2: A1/A2 The code below simulates meiosis and fertilization of 1000 offspring, makes a table, and graphs the results. # set up the different variants that each parent has parent3_variants &lt;- c(&#39;A1&#39;,&#39;A2&#39;) parent4_variants &lt;- c(&#39;A1&#39;,&#39;A2&#39;) # list of 1000 gametes from each parent, probability of each is equal by default parent3_gametes &lt;- sample(parent3_variants, 1000, replace = TRUE) parent4_gametes &lt;- sample(parent4_variants, 1000, replace = TRUE) # put gametes together to make 1000 offspring cross_x2 &lt;- paste(parent3_gametes, parent4_gametes, sep=&quot;/&quot;) cross_x2 &lt;- gsub(&quot;A2/A1&quot;, &quot;A1/A2&quot;, cross_x2) # order doesn&#39;t matter offspring2 &lt;- data.frame(table(cross_x2)) # table knitr::kable(offspring2, caption = &#39;A1/A2 inter-cross simulation&#39;, booktabs = TRUE) Table 1.3: A1/A2 inter-cross simulation cross_x2 Freq A1/A1 253 A1/A2 495 A2/A2 252 # makes a bar graph of the frequency of genotypes ggplot(offspring2, aes(x=cross_x2, y=Freq)) + geom_bar(stat=&quot;identity&quot;) How does this compare to our predicted probabilities from the tree diagram? Remember that they were: \\(p(A1/A1) = 0.25\\) \\(p(A1/A2) = 0.5\\) \\(p(A2/A2) = 0.25\\) Should be reasonably close. Just as an additional example, the same code adapted to use B and b variants of the B gene: parent1_variants &lt;- c(&#39;B&#39;,&#39;B&#39;) parent2_variants &lt;- c(&#39;b&#39;,&#39;b&#39;) parent1_gametes &lt;- sample(parent1_variants, 1000, replace = TRUE) parent2_gametes &lt;- sample(parent2_variants, 1000, replace = TRUE) cross_x1 &lt;- paste(parent1_gametes, parent2_gametes, sep=&quot;&quot;) offspring1 &lt;- data.frame(table(cross_x1)) knitr::kable(offspring1, caption = &#39;BBxbb parent cross simulation&#39;, booktabs = TRUE) Table 1.4: BBxbb parent cross simulation cross_x1 Freq Bb 1000 ggplot(offspring1, aes(x=cross_x1, y=Freq)) + geom_bar(stat=&quot;identity&quot;) Now intercross the offspring from the first cross, each is Bb: parent3_variants &lt;- c(&#39;B&#39;,&#39;b&#39;) parent4_variants &lt;- c(&#39;B&#39;,&#39;b&#39;) parent3_gametes &lt;- sample(parent3_variants, 1000, replace = TRUE) parent4_gametes &lt;- sample(parent4_variants, 1000, replace = TRUE) cross_x2 &lt;- paste(parent3_gametes, parent4_gametes, sep=&quot;&quot;) cross_x2 &lt;- gsub(&quot;bB&quot;, &quot;Bb&quot;, cross_x2) offspring2 &lt;- data.frame(table(cross_x2)) knitr::kable(offspring2, caption = &#39;Bb inter-cross simulation&#39;, booktabs = TRUE) Table 1.5: Bb inter-cross simulation cross_x2 Freq bb 239 Bb 506 BB 255 ggplot(offspring2, aes(x=cross_x2, y=Freq)) + geom_bar(stat=&quot;identity&quot;) "],
["trees.html", "Chapter 2 Tree Diagrams", " Chapter 2 Tree Diagrams Tree diagrams are very useful for probability. "],
["and-or.html", "Chapter 3 And/Or 3.1 and statements 3.2 or statements", " Chapter 3 And/Or Logic with and and or… 3.1 and statements 3.2 or statements "],
["conditional.html", "Chapter 4 Conditional Probability 4.1 Example one 4.2 Example two", " Chapter 4 Conditional Probability Conditional probability is a thing. 4.1 Example one some stuff 4.2 Example two more stuff "],
["the-binomial-distribution.html", "Chapter 5 The Binomial Distribution", " Chapter 5 The Binomial Distribution We describe some cool stuff about the Binomial Distribution in this chapter. "],
["combinations-and-permutations.html", "Chapter 6 Combinations and Permutations 6.1 Combinations 6.2 Permutations", " Chapter 6 Combinations and Permutations Combinations and Permutations 6.1 Combinations 6.2 Permutations "],
["normal.html", "Chapter 7 Normal Distribution", " Chapter 7 Normal Distribution Not everything is Normal (we certainly aren’t), but it’s useful! "],
["multinom.html", "Chapter 8 Multinomial Distribution", " Chapter 8 Multinomial Distribution Beyond the Binomial to the Multinomial… "],
["fancy.html", "Chapter 9 Fancier Distributions", " Chapter 9 Fancier Distributions Oooh, fancy! "],
["bayes.html", "Chapter 10 Bayes Theorem", " Chapter 10 Bayes Theorem Probability can give you (apparent) superpowers! "],
["references.html", "References", " References "]
]
